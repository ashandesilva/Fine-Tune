{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained YOLO11m-pose model\n",
    "model = YOLO('../yolo11n-pose.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on your dataset\n",
    "results = model.train(data='dataset.yaml', epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yolo11m-pose.pt 902frames\n",
    "```\n",
    "1/100         0G      1.829      5.763     0.4907      1.222      2.263         51        640:  28%|██▊       | 11/40 [08:26<20:51, 43.15s/it]\n",
    "\n",
    "One Epoch Time:\n",
    "Total iterations per epoch = 40\n",
    "Time per iteration = 43.15 seconds\n",
    "Time for one epoch = 40 × 43.15 seconds\n",
    "One Epoch ≈ 1,726 seconds ≈ 28.77 minutes\n",
    "Full Training Time:\n",
    "Total epochs = 100\n",
    "Time for all epochs = 100 × 1,726 seconds\n",
    "Full Training Time ≈ 172,600 seconds\n",
    "In hours: ≈ 47.94 hours\n",
    "In days: ≈ 2 days\n",
    "```\n",
    "\n",
    "---\n",
    "The \"55.64s/it\" in your training output means \"55.64 seconds per iteration\". Let me break down what this means in the context of training:\n",
    "\n",
    "1. **Iteration Time**:\n",
    "- Each iteration takes approximately 55.64 seconds to complete\n",
    "- An iteration represents processing one batch of images through the model\n",
    "\n",
    "2. **Progress Information**:\n",
    "```\n",
    "1/100         # Current epoch/Total epochs\n",
    "0G            # GPU number (0)\n",
    "2.129         # Box loss\n",
    "6.665         # Pose loss\n",
    "0.6589        # Object loss\n",
    "1.898         # Classification loss\n",
    "2.741         # Total loss\n",
    "46            # Batch size\n",
    "640           # Image size\n",
    "5%            # Progress percentage\n",
    "▌             # Progress bar\n",
    "2/40          # Current batch/Total batches\n",
    "[01:52<35:14, 55.64s/it]  # Time info: [elapsed<remaining, seconds/iteration]\n",
    "```\n",
    "\n",
    "3. **Performance Analysis**:\n",
    "- 55.64 seconds per iteration is relatively slow\n",
    "- This could be due to:\n",
    "  - Large batch size\n",
    "  - Complex model architecture\n",
    "  - Limited GPU resources\n",
    "  - Large image size (640x640)\n",
    "  - CPU bottlenecks\n",
    "\n",
    "4. **Expected Total Time**:\n",
    "- With 55.64s/iteration:\n",
    "  - One epoch ≈ 40 iterations × 55.64s = 37.09 minutes\n",
    "  - Full training (100 epochs) ≈ 61.82 hours\n",
    "\n",
    "To improve training speed, you could:\n",
    "1. Reduce batch size\n",
    "2. Use a smaller model (e.g., YOLOPose-n instead of YOLOPose-m)\n",
    "3. Use a more powerful GPU\n",
    "4. Optimize data loading\n",
    "5. Consider using mixed precision training\n",
    "\n",
    "Would you like me to explain how to implement any of these optimizations to reduce the training time?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "yolo11n-pose.pt 902frames\n",
    "```\n",
    "Let me calculate and explain the epoch training time and full training time based on the information you provided:\n",
    "\n",
    "1. **Per Iteration Time**: `7.89s/it`\n",
    "\n",
    "2. **Iterations per Epoch**:\n",
    "From your output `7/40` indicates there are 40 iterations per epoch.\n",
    "\n",
    "3. **Epoch Training Time**:\n",
    "```\n",
    "Time per epoch = Iterations per epoch × Time per iteration\n",
    "Time per epoch = 40 × 7.89 seconds\n",
    "Time per epoch = 315.6 seconds ≈ 5.26 minutes\n",
    "```\n",
    "\n",
    "4. **Full Training Time** (for 100 epochs):\n",
    "```\n",
    "Full training time = Number of epochs × Time per epoch\n",
    "Full training time = 100 × 315.6 seconds\n",
    "Full training time = 31,560 seconds\n",
    "                  ≈ 526 minutes\n",
    "                  ≈ 8.77 hours\n",
    "```\n",
    "\n",
    "Summary:\n",
    "- Single Iteration: 7.89 seconds\n",
    "- One Epoch: ~5.26 minutes\n",
    "- Full Training (100 epochs): ~8.77 hours\n",
    "\n",
    "This can be visualized as:\n",
    "```\n",
    "┌────────────────── Full Training (8.77 hours) ──────────────────┐\n",
    "│                                                                │\n",
    "│  ┌─── Epoch 1 ───┐ ┌─── Epoch 2 ───┐         ┌─── Epoch 100 ──┐\n",
    "│  │  (5.26 mins)  │ │  (5.26 mins)  │   ...   │  (5.26 mins)   │\n",
    "│  │               │ │               │         │                │\n",
    "│  │ 40 iterations │ │ 40 iterations │         │ 40 iterations  │\n",
    "│  └───────────────┘ └───────────────┘         └────────────────┘\n",
    "│                                                                │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "To potentially reduce training time, you could:\n",
    "1. Use a more powerful GPU\n",
    "2. Implement mixed precision training\n",
    "3. Optimize batch size\n",
    "4. Use data parallelism if multiple GPUs are available\n",
    "5. Optimize data loading pipeline\n",
    "\n",
    "Would you like me to explain any of these optimization techniques in detail?\n",
    "\n",
    "`7.89s/it` represents the time taken per iteration (per batch) during training. Let me break down what this means:\n",
    "\n",
    "- `7.89s`: 7.89 seconds\n",
    "- `/it`: per iteration\n",
    "\n",
    "This metric tells you that on average, your model is taking 7.89 seconds to process one batch of training data. Each iteration includes:\n",
    "1. Loading a batch of images\n",
    "2. Forward pass through the network\n",
    "3. Computing loss\n",
    "4. Backward pass (calculating gradients)\n",
    "5. Updating model weights\n",
    "\n",
    "From your training output, we can also see other important information:\n",
    "```\n",
    "1/100         0G      2.256      7.017     0.6447      1.885      2.721         43        640\n",
    "```\n",
    "Breaking this down:\n",
    "- `1/100`: Epoch 1 out of 100 total epochs\n",
    "- `0G`: GPU memory usage in gigabytes\n",
    "- `2.256`, `7.017`, `0.6447`, `1.885`, `2.721`: Various loss values\n",
    "- `43`: Number of targets/objects detected\n",
    "- `640`: Image size\n",
    "\n",
    "The `7.89s/it` seems relatively high, which could be due to:\n",
    "1. Large batch size\n",
    "2. Complex model architecture\n",
    "3. CPU processing instead of GPU\n",
    "4. Limited computational resources\n",
    "5. Large image size (640x640)\n",
    "\n",
    "To improve training speed, you could:\n",
    "1. Reduce batch size\n",
    "2. Use GPU if not already using one\n",
    "3. Reduce image size (though this might affect accuracy)\n",
    "4. Optimize data loading pipeline\n",
    "5. Use mixed precision training\n",
    "\n",
    "Would you like me to explain how to implement any of these optimizations to reduce the training time per iteration?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
